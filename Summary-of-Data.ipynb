{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data\n",
    " \n",
    "This notebook counts the urls, sample size, articles, and articles harvested for each of the 10 shootings examined. Scroll to the very bottom to see the table. \n",
    "\n",
    "*Remaining Questions:*\n",
    "- How do we manage the different sample sizes and different number of results for each query?\n",
    "- The Virginia Beach shooting timeline overlaps with another major shooting so we have few articles in the first two months and then over 1000 in the last - how do we manage this?\n",
    "\n",
    "*To do:*\n",
    "- Run a regression on the number of articles available and the shootings variables to see if there are correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import All_Functions as af\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegas_first_month = af.import_csv('newspaper-urls\\Vegas_first_month')\n",
    "vegas_second_month = af.import_csv('newspaper-urls\\Vegas_second_month')\n",
    "vegas_third_month = af.import_csv('newspaper-urls\\Vegas_third_month')\n",
    "\n",
    "dc_first_month = af.import_csv('newspaper-urls\\DC_first_month')\n",
    "dc_second_month = af.import_csv('newspaper-urls\\DC_second_month')\n",
    "dc_third_month = af.import_csv('newspaper-urls\\DC_third_month')\n",
    "\n",
    "houston_first_month = af.import_csv('newspaper-urls\\Houston_first_month')\n",
    "houston_second_month = af.import_csv('newspaper-urls\\Houston_second_month')\n",
    "houston_third_month = af.import_csv('newspaper-urls\\Houston_third_month')\n",
    "\n",
    "plano_first_month = af.import_csv('newspaper-urls\\Plano_first_month')\n",
    "plano_second_month = af.import_csv('newspaper-urls\\Plano_second_month')\n",
    "plano_third_month = af.import_csv('newspaper-urls\\Plano_third_month')\n",
    "\n",
    "bogue_first_month = af.import_csv('newspaper-urls\\Bogue_first_month.csv')\n",
    "bogue_second_month = af.import_csv('newspaper-urls\\Bogue_second_month.csv')\n",
    "bogue_third_month = af.import_csv('newspaper-urls\\Bogue_third_month.csv')\n",
    "\n",
    "boulder_first_month = af.import_csv('newspaper-urls\\Boulder_first_month.csv')\n",
    "boulder_second_month = af.import_csv('newspaper-urls\\Boulder_second_month.csv')\n",
    "boulder_third_month = af.import_csv('newspaper-urls\\Boulder_third_month.csv')\n",
    "\n",
    "odessa_first_month = af.import_csv('newspaper-urls\\Odessa_first_month.csv')\n",
    "odessa_second_month = af.import_csv('newspaper-urls\\Odessa_second_month.csv')\n",
    "odessa_third_month = af.import_csv('newspaper-urls\\Odessa_third_month.csv')\n",
    "\n",
    "sanbern_first_month = af.import_csv('newspaper-urls\\SanBernadino_first_month.csv')\n",
    "sanbern_second_month = af.import_csv('newspaper-urls\\SanBernadino_second_month.csv')\n",
    "sanbern_third_month = af.import_csv('newspaper-urls\\SanBernadino_third_month.csv')\n",
    "\n",
    "pittsburgh_first_month = af.import_csv('newspaper-urls\\Pittsburgh_first_month.csv')\n",
    "pittsburgh_second_month = af.import_csv('newspaper-urls\\Pittsburgh_second_month.csv')\n",
    "pittsburgh_third_month = af.import_csv('newspaper-urls\\Pittsburgh_third_month.csv')\n",
    "\n",
    "virginia_first_month = af.import_csv('newspaper-urls\\VirginiaBeach_first_month.csv')\n",
    "virginia_second_month = af.import_csv('newspaper-urls\\VirginiaBeach_second_month.csv')\n",
    "virginia_third_month = af.import_csv('newspaper-urls\\VirginiaBeach_third_month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegas_count = len(vegas_first_month) + len(vegas_second_month) + len(vegas_third_month)\n",
    "dc_count = len(dc_first_month) + len(dc_second_month) + len(dc_third_month)\n",
    "houston_count = len(houston_first_month) + len(houston_second_month) + len(houston_third_month)\n",
    "plano_count = len(plano_first_month) + len(plano_second_month) + len(plano_third_month)\n",
    "bogue_count = len(bogue_first_month) + len(bogue_second_month) + len(bogue_third_month)\n",
    "boulder_count = len(boulder_first_month) + len(boulder_second_month) + len(boulder_third_month)\n",
    "odessa_count = len(odessa_first_month) + len(odessa_second_month) + len(odessa_third_month)\n",
    "sanbern_count = len(sanbern_first_month) + len(sanbern_second_month) + len(sanbern_third_month)\n",
    "pittsburgh_count = len(pittsburgh_first_month) + len(pittsburgh_second_month) + len(pittsburgh_third_month)\n",
    "virginia_count = len(virginia_first_month) + len(virginia_second_month) + len(virginia_third_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegas_first_text = pd.read_csv('newspaper-text\\Vegas_Text-first-month.csv')\n",
    "vegas_second_text = pd.read_csv('newspaper-text\\Vegas_Text-second-month.csv')\n",
    "vegas_third_text = pd.read_csv('newspaper-text\\Vegas_Text-third-month.csv')\n",
    "\n",
    "dc_first_text =pd.read_csv('newspaper-text\\DC_Text-first-month.csv')\n",
    "dc_second_text = pd.read_csv('newspaper-text\\DC_Text-second-month.csv')\n",
    "dc_third_text = pd.read_csv('newspaper-text\\DC_Text-third-month.csv')\n",
    "\n",
    "houston_first_text = pd.read_csv('newspaper-text\\Houston_Text-first-month.csv')\n",
    "houston_second_text = pd.read_csv('newspaper-text\\Houston_Text-second-month.csv')\n",
    "houston_third_text =pd.read_csv('newspaper-text\\Houston_Text-third-month.csv')\n",
    "\n",
    "plano_first_text = pd.read_csv('newspaper-text\\Plano_Text-first-month.csv')\n",
    "plano_second_text = pd.read_csv('newspaper-text\\Plano_Text-second-month.csv')\n",
    "plano_third_text =pd.read_csv('newspaper-text\\Plano_Text-third-month.csv')\n",
    "\n",
    "bogue_first_text = pd.read_csv('newspaper-text\\Bogue_Text-first-month.csv')\n",
    "bogue_second_text = pd.read_csv('newspaper-text\\Bogue_Text-second-month.csv')\n",
    "bogue_third_text =pd.read_csv('newspaper-text\\Bogue_Text-third-month.csv')\n",
    "\n",
    "boulder_first_text = pd.read_csv('newspaper-text\\Boulder_Text-first-month.csv')\n",
    "boulder_second_text = pd.read_csv('newspaper-text\\Boulder_Text-second-month.csv')\n",
    "boulder_third_text =pd.read_csv('newspaper-text\\Boulder_Text-third-month.csv')\n",
    "\n",
    "odessa_first_text = pd.read_csv('newspaper-text\\Odessa_Text-first-month.csv')\n",
    "odessa_second_text = pd.read_csv('newspaper-text\\Odessa_Text-second-month.csv')\n",
    "odessa_third_text =pd.read_csv('newspaper-text\\Odessa_Text-third-month.csv')\n",
    "\n",
    "sanbern_first_text = pd.read_csv('newspaper-text\\SanBernadino_Text-first-month.csv')\n",
    "sanbern_second_text = pd.read_csv('newspaper-text\\SanBernadino_Text-second-month.csv')\n",
    "sanbern_third_text =pd.read_csv('newspaper-text\\SanBernadino_Text-third-month.csv')\n",
    "\n",
    "pittsburgh_first_text = pd.read_csv('newspaper-text\\Pittsburgh_Text-first-month.csv')\n",
    "pittsburgh_second_text = pd.read_csv('newspaper-text\\Pittsburgh_Text-second-month.csv')\n",
    "pittsburgh_third_text =pd.read_csv('newspaper-text\\Pittsburgh_Text-third-month.csv')\n",
    "\n",
    "virginia_first_text = pd.read_csv('newspaper-text\\VirginiaBeach_Text-first-month.csv')\n",
    "virginia_second_text = pd.read_csv('newspaper-text\\VirginiaBeach_Text-second-month.csv')\n",
    "virginia_third_text =pd.read_csv('newspaper-text\\VirginiaBeach_Text-third-month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegas_count_text = len(vegas_first_text) + len(vegas_second_text) + len(vegas_third_text)\n",
    "dc_count_text = len(dc_first_text) + len(dc_second_text) + len(dc_third_text)\n",
    "houston_count_text = len(houston_first_text) + len(houston_second_text) + len(houston_third_text)\n",
    "plano_count_text = len(plano_first_text) + len(plano_second_text) + len(plano_third_text)\n",
    "\n",
    "bogue_count_text = len(bogue_first_text) + len(bogue_second_text) + len(bogue_third_text)\n",
    "boulder_count_text = len(boulder_first_text) + len(boulder_second_text) + len(boulder_third_text)\n",
    "odessa_count_text = len(odessa_first_text) + len(odessa_second_text) + len(odessa_third_text)\n",
    "sanbern_count_text = len(sanbern_first_text) + len(sanbern_second_text) + len(sanbern_third_text)\n",
    "\n",
    "pittsburgh_count_text = len(pittsburgh_first_text) + len(pittsburgh_second_text) + len(pittsburgh_third_text)\n",
    "virginia_count_text = len(virginia_first_text) + len(virginia_second_text) + len(virginia_third_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th># urls</th>\n",
       "      <th># articles gathered</th>\n",
       "      <th>gathered/ urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>8426</td>\n",
       "      <td>4347</td>\n",
       "      <td>0.515903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DC</td>\n",
       "      <td>975</td>\n",
       "      <td>388</td>\n",
       "      <td>0.397949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston</td>\n",
       "      <td>1925</td>\n",
       "      <td>918</td>\n",
       "      <td>0.476883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plano</td>\n",
       "      <td>8212</td>\n",
       "      <td>4238</td>\n",
       "      <td>0.516074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bogue</td>\n",
       "      <td>1190</td>\n",
       "      <td>579</td>\n",
       "      <td>0.486555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>3615</td>\n",
       "      <td>2280</td>\n",
       "      <td>0.630705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Odessa</td>\n",
       "      <td>3273</td>\n",
       "      <td>1726</td>\n",
       "      <td>0.527345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>4239</td>\n",
       "      <td>1801</td>\n",
       "      <td>0.424864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>3653</td>\n",
       "      <td>1851</td>\n",
       "      <td>0.506707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>6794</td>\n",
       "      <td>3566</td>\n",
       "      <td>0.524875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Location # urls # articles gathered  gathered/ urls\n",
       "0           Vegas   8426                4347        0.515903\n",
       "1              DC    975                 388        0.397949\n",
       "2         Houston   1925                 918        0.476883\n",
       "3           Plano   8212                4238        0.516074\n",
       "4           Bogue   1190                 579        0.486555\n",
       "5         Boulder   3615                2280        0.630705\n",
       "6          Odessa   3273                1726        0.527345\n",
       "7  San Bernardino   4239                1801        0.424864\n",
       "8      Pittsburgh   3653                1851        0.506707\n",
       "9  Virginia Beach   6794                3566        0.524875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([['Vegas','DC','Houston','Plano','Bogue','Boulder','Odessa','San Bernardino','Pittsburgh','Virginia Beach'],[vegas_count,dc_count,houston_count,plano_count,bogue_count, boulder_count,odessa_count,sanbern_count,pittsburgh_count,virginia_count],\n",
    "                   [vegas_count_text,dc_count_text,houston_count_text,plano_count_text,bogue_count_text,boulder_count_text,odessa_count_text,sanbern_count_text, pittsburgh_count_text,virginia_count_text]]).T\n",
    "\n",
    "df.columns=['Location','# urls','# articles gathered']\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[index,'gathered/ urls']=df.loc[index,'# articles gathered']/df.loc[index,'# urls']\n",
    "#     df.loc[index,'gathered/ sample size']=df.loc[index,'# articles gathered']/df.loc[index,'sample size']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4230.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['# urls'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2169.4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['# articles gathered'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5007860049961378"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gathered/ urls'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42302"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['# urls'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

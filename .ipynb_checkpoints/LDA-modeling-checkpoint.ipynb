{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import glob\n",
    "import All_Functions as af\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files_to_df(paths):\n",
    "#     first_df = pd.read_csv(paths[0])\n",
    "    for path in paths[1:]:\n",
    "        print(f\"Appendings {path}\")\n",
    "        first_df = pd.read_csv(paths[0])\n",
    "        new_df = first_df.append(pd.read_csv(path), ignore_index=True)\n",
    "        print(len(new_df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the version 2 text files\n",
    "all_files = [x for x in glob.glob('newspaper-text' + \"/*.csv\") if \"v2\" in x]\n",
    "all_text = af.import_text_data(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.sample(range(1, len(compact_list)), 7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n"
     ]
    }
   ],
   "source": [
    "# Put all text into a single df \n",
    "compact_list =[all_text[0][0]]\n",
    "for dataset in all_text: # THERES a memeory problem with using the full dataset at the doc term matrix step!!!!\n",
    "    for i in range(1,len(dataset)):\n",
    "        compact_list.append(dataset[i])\n",
    "        \n",
    "sample = random.sample(range(1, len(compact_list)), 7000)\n",
    "\n",
    "sample_list = [compact_list[i] for i in range(len(compact_list)) if i in sample]\n",
    "print(len(sample_list))\n",
    "\n",
    "df = pd.DataFrame(data=sample_list, columns=compact_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 20.6 GiB for an array with shape (7000,) and data type <U788191",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-d8dea43a7e33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\"\n\u001b[0;32m      6\u001b[0m \u001b[0mcount_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdoc_term_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'U'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 20.6 GiB for an array with shape (7000,) and data type <U788191"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use CountVectorizer to create a document-term matrix \n",
    "The paramters mean that we're only including words that appear in less than 80% of the document and in at least 2 documents\n",
    "Also removing stopwords\n",
    "\"\"\"\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(df['text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5891x40138 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1856828 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This means that each of the 20000 documents is represented as a vector with \n",
    "1456 dimension - so our vocabulary has 14546 words'''\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "n_components specifics the number of topics that we want our text to be divided into\n",
    "random_state is the seed so you can replicate your results \n",
    "'''\n",
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['boulder', 'gun', 'news', 'school', 'victims', 'year', 'killed', 'people', 'police', 'said']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['house', 'control', 'guns', 'state', 'trump', 'people', 'biden', 'president', 'said', 'gun']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['lot', 'say', 'community', 'june', 'know', 'want', 'think', 'going', 'like', 'people']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['2017', 'community', 'people', 'year', '12', 'nightclub', 'asian', 'june', 'pulse', 'orlando']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['use', 'media', 'time', 'right', 'new', 'court', 'like', 'gun', 'trump', 'people']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5891, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "'''output means that each of the documents have 5 columns where each column \n",
    "corresponds to the probabilitiy value of a particular topic'''\n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>title</th>\n",
       "      <th>themes</th>\n",
       "      <th>media_id</th>\n",
       "      <th>media_url</th>\n",
       "      <th>Leaning</th>\n",
       "      <th>Location</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://www.inquisitr.com/4260803/new-pulse-nig...</td>\n",
       "      <td>june 12 2016 lone gunman omar mateen walked or...</td>\n",
       "      <td>{'neg': 0.143, 'neu': 0.768, 'pos': 0.089, 'co...</td>\n",
       "      <td>2017-06-01 06:18:21</td>\n",
       "      <td>New Pulse Nightclub Massacre Footage Released:...</td>\n",
       "      <td></td>\n",
       "      <td>26924</td>\n",
       "      <td>http://www.inquisitr.com</td>\n",
       "      <td>Center Left</td>\n",
       "      <td>Bogue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://feedproxy.google.com/~r/uproxx/features...</td>\n",
       "      <td>bill maher stranger controversy insufferably s...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.776, 'pos': 0.134, 'com...</td>\n",
       "      <td>2017-06-03 06:54:36</td>\n",
       "      <td>Bill Maher Is Under Fire For Using A Derogator...</td>\n",
       "      <td></td>\n",
       "      <td>68816</td>\n",
       "      <td>http://www.uproxx.com/#spider</td>\n",
       "      <td>Center Left</td>\n",
       "      <td>Bogue</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.thewrap.com/multiple-fatalities-orl...</td>\n",
       "      <td>incident comes week one-year anniversary pulse...</td>\n",
       "      <td>{'neg': 0.295, 'neu': 0.676, 'pos': 0.029, 'co...</td>\n",
       "      <td>2017-06-05 10:17:23</td>\n",
       "      <td>&amp;#8216;Multiple Fatalities&amp;#8217; in Orlando W...</td>\n",
       "      <td></td>\n",
       "      <td>18704</td>\n",
       "      <td>http://www.thewrap.com</td>\n",
       "      <td>center</td>\n",
       "      <td>Bogue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://feedproxy.google.com/~r/time/topstories...</td>\n",
       "      <td>least five people killed monday disgruntled em...</td>\n",
       "      <td>{'neg': 0.224, 'neu': 0.74, 'pos': 0.036, 'com...</td>\n",
       "      <td>2017-06-05 11:46:24</td>\n",
       "      <td>‘Disgruntled’ Ex-Employee Kills 5 in Orlando S...</td>\n",
       "      <td></td>\n",
       "      <td>40362</td>\n",
       "      <td>http://www.time.com/time/</td>\n",
       "      <td>Bogue</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.denverpost.com/2017/06/05/florida-w...</td>\n",
       "      <td>trending terrance harris mike schneider associ...</td>\n",
       "      <td>{'neg': 0.185, 'neu': 0.774, 'pos': 0.041, 'co...</td>\n",
       "      <td>2017-06-05 23:54:13</td>\n",
       "      <td>Florida sheriff: Fired worker killed 5, shot s...</td>\n",
       "      <td></td>\n",
       "      <td>390346</td>\n",
       "      <td>http://feeds.denverpost.com/dp-news-breaking</td>\n",
       "      <td>Center Left</td>\n",
       "      <td>Bogue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0  0  http://www.inquisitr.com/4260803/new-pulse-nig...   \n",
       "1  1  http://feedproxy.google.com/~r/uproxx/features...   \n",
       "2  2  http://www.thewrap.com/multiple-fatalities-orl...   \n",
       "3  3  http://feedproxy.google.com/~r/time/topstories...   \n",
       "4  4  http://www.denverpost.com/2017/06/05/florida-w...   \n",
       "\n",
       "                                                text  \\\n",
       "0  june 12 2016 lone gunman omar mateen walked or...   \n",
       "1  bill maher stranger controversy insufferably s...   \n",
       "2  incident comes week one-year anniversary pulse...   \n",
       "3  least five people killed monday disgruntled em...   \n",
       "4  trending terrance harris mike schneider associ...   \n",
       "\n",
       "                                           sentiment         publish_date  \\\n",
       "0  {'neg': 0.143, 'neu': 0.768, 'pos': 0.089, 'co...  2017-06-01 06:18:21   \n",
       "1  {'neg': 0.09, 'neu': 0.776, 'pos': 0.134, 'com...  2017-06-03 06:54:36   \n",
       "2  {'neg': 0.295, 'neu': 0.676, 'pos': 0.029, 'co...  2017-06-05 10:17:23   \n",
       "3  {'neg': 0.224, 'neu': 0.74, 'pos': 0.036, 'com...  2017-06-05 11:46:24   \n",
       "4  {'neg': 0.185, 'neu': 0.774, 'pos': 0.041, 'co...  2017-06-05 23:54:13   \n",
       "\n",
       "                                               title themes media_id  \\\n",
       "0  New Pulse Nightclub Massacre Footage Released:...           26924   \n",
       "1  Bill Maher Is Under Fire For Using A Derogator...           68816   \n",
       "2  &#8216;Multiple Fatalities&#8217; in Orlando W...           18704   \n",
       "3  ‘Disgruntled’ Ex-Employee Kills 5 in Orlando S...           40362   \n",
       "4  Florida sheriff: Fired worker killed 5, shot s...          390346   \n",
       "\n",
       "                                      media_url      Leaning Location  Topic  \n",
       "0                      http://www.inquisitr.com  Center Left    Bogue      0  \n",
       "1                 http://www.uproxx.com/#spider  Center Left    Bogue      4  \n",
       "2                        http://www.thewrap.com       center    Bogue      0  \n",
       "3                     http://www.time.com/time/        Bogue     None      0  \n",
       "4  http://feeds.denverpost.com/dp-news-breaking  Center Left    Bogue      0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Topic'] = topic_values.argmax(axis=1)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
